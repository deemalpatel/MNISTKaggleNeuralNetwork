{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('test.csv')\n",
    "trainData = pd.read_csv('train.csv')\n",
    "y = trainData.label\n",
    "X = trainData.drop('label', axis=1)\n",
    "global modelNum\n",
    "modelNum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel0      False\n",
      "pixel1      False\n",
      "pixel2      False\n",
      "pixel3      False\n",
      "pixel4      False\n",
      "            ...  \n",
      "pixel779    False\n",
      "pixel780    False\n",
      "pixel781    False\n",
      "pixel782    False\n",
      "pixel783    False\n",
      "Length: 784, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(X.isnull().any()==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995       0       0       0       0       0       0       0       0       0   \n",
       "41996       0       0       0       0       0       0       0       0       0   \n",
       "41997       0       0       0       0       0       0       0       0       0   \n",
       "41998       0       0       0       0       0       0       0       0       0   \n",
       "41999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 784 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        4\n",
       "4        0\n",
       "        ..\n",
       "41995    0\n",
       "41996    1\n",
       "41997    7\n",
       "41998    6\n",
       "41999    9\n",
       "Name: label, Length: 42000, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26906    0\n",
       "38602    9\n",
       "10316    2\n",
       "27806    3\n",
       "31367    2\n",
       "        ..\n",
       "11345    9\n",
       "11769    6\n",
       "28685    5\n",
       "8159     8\n",
       "11703    1\n",
       "Name: label, Length: 22050, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLayer10NodeModel = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(784,)),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(model, loss, optimizer):\n",
    "    global history\n",
    "    model.compile(loss = loss, optimizer = optimizer, metrics = ['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "\n",
    "def predictModel(model):\n",
    "    global trainDF\n",
    "    global modelNum\n",
    "    print('Test accuracy',model.evaluate(X_test,y_test)[1])\n",
    "    y_pred = model.predict(testData)\n",
    "    y_pred_classes = np.argmax(y_pred, axis = 1)\n",
    "    trainDF = pd.DataFrame(y_pred_classes, columns = ['Label'])\n",
    "    trainDF.index.name = 'ImageId'\n",
    "    trainDF.index += 1\n",
    "    trainDF.to_csv(f'model{modelNum}prediction.csv')\n",
    "    modelNum+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layers, 10 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 3s 3ms/step - loss: 6.1829 - accuracy: 0.1696 - val_loss: 1.7055 - val_accuracy: 0.3697\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.6202 - accuracy: 0.3751 - val_loss: 1.4689 - val_accuracy: 0.4061\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.4369 - accuracy: 0.4163 - val_loss: 1.3592 - val_accuracy: 0.4653\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.3200 - accuracy: 0.4527 - val_loss: 1.3021 - val_accuracy: 0.4592\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.2626 - accuracy: 0.4690 - val_loss: 1.2308 - val_accuracy: 0.5038\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.1862 - accuracy: 0.5150 - val_loss: 1.1615 - val_accuracy: 0.5597\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.1348 - accuracy: 0.5427 - val_loss: 1.0968 - val_accuracy: 0.5556\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.0642 - accuracy: 0.5672 - val_loss: 1.0640 - val_accuracy: 0.5963\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.0509 - accuracy: 0.5757 - val_loss: 1.0658 - val_accuracy: 0.5876\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.0162 - accuracy: 0.5936 - val_loss: 1.0447 - val_accuracy: 0.5984\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.9800 - accuracy: 0.6052 - val_loss: 1.0057 - val_accuracy: 0.6244\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.9555 - accuracy: 0.6263 - val_loss: 0.9700 - val_accuracy: 0.6437\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.9170 - accuracy: 0.6406 - val_loss: 0.9372 - val_accuracy: 0.6565\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.8836 - accuracy: 0.6587 - val_loss: 0.9385 - val_accuracy: 0.6642\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.6822 - val_loss: 0.8717 - val_accuracy: 0.6657\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.7746 - accuracy: 0.6942 - val_loss: 0.8540 - val_accuracy: 0.6899\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.7368 - accuracy: 0.7113 - val_loss: 0.7893 - val_accuracy: 0.7072\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.7031 - accuracy: 0.7280 - val_loss: 0.7576 - val_accuracy: 0.7222\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6762 - accuracy: 0.7372 - val_loss: 0.7307 - val_accuracy: 0.7352\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.7043 - accuracy: 0.7329 - val_loss: 0.7145 - val_accuracy: 0.7374\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6573 - accuracy: 0.7447 - val_loss: 0.7244 - val_accuracy: 0.7239\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6512 - accuracy: 0.7526 - val_loss: 0.6998 - val_accuracy: 0.7529\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6148 - accuracy: 0.7723 - val_loss: 0.7080 - val_accuracy: 0.7697\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5966 - accuracy: 0.7878 - val_loss: 0.7331 - val_accuracy: 0.7733\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.8069 - val_loss: 0.6731 - val_accuracy: 0.7966\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5827 - accuracy: 0.8198 - val_loss: 0.7225 - val_accuracy: 0.7916\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.5569 - accuracy: 0.8339 - val_loss: 0.6441 - val_accuracy: 0.8241\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5137 - accuracy: 0.8483 - val_loss: 0.5953 - val_accuracy: 0.8250\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.8471 - val_loss: 0.6598 - val_accuracy: 0.7981\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.8433 - val_loss: 0.6467 - val_accuracy: 0.8207\n",
      "Time taken to fit 2 layers with 10 nodes each: 0:00:30.537489\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(twoLayer10NodeModel,'categorical_crossentropy','adam')\n",
    "end = dt.datetime.now()\n",
    "twoLayer10NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 2 layers with 10 nodes each: {twoLayer10NodeModelFitTime}')\n",
    "# Kaggle Score: 0.82828, Username: Deemal Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.8267\n",
      "Test accuracy 0.8266666531562805\n"
     ]
    }
   ],
   "source": [
    "predictModel(twoLayer10NodeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 2.6486 - accuracy: 0.3008 - val_loss: 1.5713 - val_accuracy: 0.4106\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 1.6033 - accuracy: 0.3758 - val_loss: 1.5078 - val_accuracy: 0.3780\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5391 - accuracy: 0.3734 - val_loss: 1.6506 - val_accuracy: 0.2973\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.6566 - accuracy: 0.3022 - val_loss: 1.6134 - val_accuracy: 0.3091\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5971 - accuracy: 0.3100 - val_loss: 1.5891 - val_accuracy: 0.3056\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5779 - accuracy: 0.3103 - val_loss: 1.5828 - val_accuracy: 0.3063\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5842 - accuracy: 0.3039 - val_loss: 1.6956 - val_accuracy: 0.2819\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5833 - accuracy: 0.3018 - val_loss: 1.5664 - val_accuracy: 0.3060\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5585 - accuracy: 0.3053 - val_loss: 1.5826 - val_accuracy: 0.3069\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5763 - accuracy: 0.2977 - val_loss: 1.5640 - val_accuracy: 0.3026\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5699 - accuracy: 0.3034 - val_loss: 1.7740 - val_accuracy: 0.2844\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.6872 - accuracy: 0.2918 - val_loss: 1.6148 - val_accuracy: 0.3027\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 1s 954us/step - loss: 1.8387 - accuracy: 0.2907 - val_loss: 1.5970 - val_accuracy: 0.3024\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 1s 939us/step - loss: 1.6176 - accuracy: 0.3022 - val_loss: 1.5961 - val_accuracy: 0.3003\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 1s 961us/step - loss: 1.6738 - accuracy: 0.3013 - val_loss: 1.6612 - val_accuracy: 0.2929\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 1s 995us/step - loss: 1.6824 - accuracy: 0.2865 - val_loss: 1.6583 - val_accuracy: 0.3026\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 1s 986us/step - loss: 1.6641 - accuracy: 0.2915 - val_loss: 1.6150 - val_accuracy: 0.3008\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 1s 960us/step - loss: 1.5942 - accuracy: 0.2956 - val_loss: 1.6168 - val_accuracy: 0.2969\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 1s 941us/step - loss: 1.6296 - accuracy: 0.3030 - val_loss: 1.6301 - val_accuracy: 0.2946\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.6199 - accuracy: 0.3002 - val_loss: 2.0314 - val_accuracy: 0.2823\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.7456 - accuracy: 0.2947 - val_loss: 2.1318 - val_accuracy: 0.1901\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 2.0722 - accuracy: 0.1915 - val_loss: 2.0028 - val_accuracy: 0.1913\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.9636 - accuracy: 0.1939 - val_loss: 1.9162 - val_accuracy: 0.1946\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.9004 - accuracy: 0.1943 - val_loss: 1.8707 - val_accuracy: 0.1962\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.7715 - accuracy: 0.2569 - val_loss: 1.6463 - val_accuracy: 0.2946\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.6221 - accuracy: 0.3124 - val_loss: 1.5788 - val_accuracy: 0.3293\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5337 - accuracy: 0.3397 - val_loss: 1.4908 - val_accuracy: 0.3558\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5416 - accuracy: 0.3501 - val_loss: 1.5839 - val_accuracy: 0.3533\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.7066 - accuracy: 0.3095 - val_loss: 1.4953 - val_accuracy: 0.3796\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.4791 - accuracy: 0.3731 - val_loss: 1.4545 - val_accuracy: 0.3852\n",
      "Time taken to fit 2 layers with 10 nodes each: 0:00:24.243876\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(twoLayer10NodeModel,'categorical_crossentropy','sgd')\n",
    "end = dt.datetime.now()\n",
    "twoLayer10NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 2 layers with 10 nodes each: {twoLayer10NodeModelFitTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layers, 20 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLayer20NodeModel = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(784,)),\n",
    "    keras.layers.Dense(20, activation = 'relu'),\n",
    "    keras.layers.Dense(20, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 8.1893 - accuracy: 0.2541 - val_loss: 1.5790 - val_accuracy: 0.4339\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.5183 - accuracy: 0.4333 - val_loss: 1.2922 - val_accuracy: 0.4831\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.2821 - accuracy: 0.4938 - val_loss: 1.2162 - val_accuracy: 0.5127\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.1791 - accuracy: 0.5136 - val_loss: 1.0602 - val_accuracy: 0.5924\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.0083 - accuracy: 0.6024 - val_loss: 1.0313 - val_accuracy: 0.6004\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.9469 - accuracy: 0.6253 - val_loss: 0.9058 - val_accuracy: 0.6773\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.8403 - accuracy: 0.6946 - val_loss: 0.8384 - val_accuracy: 0.6935\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.8155 - accuracy: 0.6987 - val_loss: 0.8355 - val_accuracy: 0.7080\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.7538 - accuracy: 0.7390 - val_loss: 0.7992 - val_accuracy: 0.7284\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.7455 - accuracy: 0.7420 - val_loss: 0.7592 - val_accuracy: 0.7556\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.7329 - accuracy: 0.7530 - val_loss: 0.7651 - val_accuracy: 0.7422\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.7093 - accuracy: 0.7600 - val_loss: 0.7586 - val_accuracy: 0.7728\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6770 - accuracy: 0.7778 - val_loss: 0.7155 - val_accuracy: 0.7789\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6502 - accuracy: 0.7837 - val_loss: 0.6732 - val_accuracy: 0.7971\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6366 - accuracy: 0.7921 - val_loss: 0.6323 - val_accuracy: 0.8031\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6372 - accuracy: 0.7928 - val_loss: 0.6486 - val_accuracy: 0.8003\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6058 - accuracy: 0.8064 - val_loss: 0.6586 - val_accuracy: 0.8022\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6052 - accuracy: 0.8050 - val_loss: 0.6835 - val_accuracy: 0.7922\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6036 - accuracy: 0.8116 - val_loss: 0.6320 - val_accuracy: 0.8114\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5850 - accuracy: 0.8143 - val_loss: 0.6066 - val_accuracy: 0.8234\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5746 - accuracy: 0.8195 - val_loss: 0.7419 - val_accuracy: 0.7936\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5606 - accuracy: 0.8239 - val_loss: 0.5616 - val_accuracy: 0.8442\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5040 - accuracy: 0.8502 - val_loss: 0.5676 - val_accuracy: 0.8464\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4809 - accuracy: 0.8525 - val_loss: 0.5213 - val_accuracy: 0.8599\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4589 - accuracy: 0.8616 - val_loss: 0.5524 - val_accuracy: 0.8359\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4626 - accuracy: 0.8597 - val_loss: 0.5002 - val_accuracy: 0.8597\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4520 - accuracy: 0.8629 - val_loss: 0.5085 - val_accuracy: 0.8607\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4350 - accuracy: 0.8664 - val_loss: 0.5048 - val_accuracy: 0.8520\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4211 - accuracy: 0.8723 - val_loss: 0.5032 - val_accuracy: 0.8574\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4186 - accuracy: 0.8739 - val_loss: 0.6340 - val_accuracy: 0.8048\n",
      "Time taken to fit 2 layers with 20 nodes each: 0:00:25.317533\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(twoLayer20NodeModel,'categorical_crossentropy','adam')\n",
    "end = dt.datetime.now()\n",
    "twoLayer20NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 2 layers with 20 nodes each: {twoLayer20NodeModelFitTime}')\n",
    "# Kaggle Score: 0.79800, Username: Deemal Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 0s 731us/step - loss: 0.6541 - accuracy: 0.7987\n",
      "Test accuracy 0.7986508011817932\n"
     ]
    }
   ],
   "source": [
    "predictModel(twoLayer20NodeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 1.8952 - accuracy: 0.4240 - val_loss: 1.2289 - val_accuracy: 0.5358\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.0839 - accuracy: 0.5516 - val_loss: 1.2587 - val_accuracy: 0.4637\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.9561 - accuracy: 0.5857 - val_loss: 0.9137 - val_accuracy: 0.6299\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.1032 - accuracy: 0.5600 - val_loss: 0.9186 - val_accuracy: 0.6341\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.9521 - accuracy: 0.6093 - val_loss: 1.2589 - val_accuracy: 0.4989\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 1s 962us/step - loss: 1.2387 - accuracy: 0.4890 - val_loss: 1.3368 - val_accuracy: 0.4758\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.1310 - accuracy: 0.5332 - val_loss: 1.0209 - val_accuracy: 0.5642\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.2323 - accuracy: 0.4936 - val_loss: 1.2536 - val_accuracy: 0.4769\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.2009 - accuracy: 0.4860 - val_loss: 1.0408 - val_accuracy: 0.5737\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 1s 949us/step - loss: 1.0948 - accuracy: 0.5442 - val_loss: 1.0417 - val_accuracy: 0.5506\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.0009 - accuracy: 0.5720 - val_loss: 1.0147 - val_accuracy: 0.6075\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 1s 952us/step - loss: 1.0327 - accuracy: 0.5762 - val_loss: 1.0374 - val_accuracy: 0.5684\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.0544 - accuracy: 0.5663 - val_loss: 1.7666 - val_accuracy: 0.4767\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 1s 972us/step - loss: 1.1288 - accuracy: 0.5060 - val_loss: 1.1936 - val_accuracy: 0.4833\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 1s 970us/step - loss: 1.1453 - accuracy: 0.4751 - val_loss: 1.1235 - val_accuracy: 0.4882\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 1s 982us/step - loss: 1.1125 - accuracy: 0.4811 - val_loss: 1.1286 - val_accuracy: 0.4879\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.1249 - accuracy: 0.4902 - val_loss: 1.4157 - val_accuracy: 0.4595\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 1s 959us/step - loss: 1.1244 - accuracy: 0.4805 - val_loss: 1.1172 - val_accuracy: 0.4891\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 1s 951us/step - loss: 1.1255 - accuracy: 0.4714 - val_loss: 1.1590 - val_accuracy: 0.4884\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 1s 957us/step - loss: 1.1737 - accuracy: 0.4737 - val_loss: 1.1564 - val_accuracy: 0.4769\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 1s 991us/step - loss: 1.2092 - accuracy: 0.4607 - val_loss: 1.1696 - val_accuracy: 0.4884\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.3572 - accuracy: 0.4540 - val_loss: 1.4832 - val_accuracy: 0.4080\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.4236 - accuracy: 0.4077 - val_loss: 1.1978 - val_accuracy: 0.4725\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 1s 990us/step - loss: 1.1676 - accuracy: 0.4734 - val_loss: 1.1470 - val_accuracy: 0.4856\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 1.1291 - accuracy: 0.4828 - val_loss: 1.1504 - val_accuracy: 0.4886\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 1s 981us/step - loss: 1.1145 - accuracy: 0.4827 - val_loss: 1.1784 - val_accuracy: 0.4864\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 1s 980us/step - loss: 1.1357 - accuracy: 0.4749 - val_loss: 1.1339 - val_accuracy: 0.4762\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 1s 987us/step - loss: 1.0975 - accuracy: 0.4822 - val_loss: 1.1481 - val_accuracy: 0.4804\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 1s 970us/step - loss: 1.1341 - accuracy: 0.4733 - val_loss: 1.1623 - val_accuracy: 0.4838\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 1s 998us/step - loss: 1.2210 - accuracy: 0.4628 - val_loss: 1.2263 - val_accuracy: 0.4733\n",
      "Time taken to fit 2 layers with 20 nodes each: 0:00:22.404917\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(twoLayer20NodeModel,'categorical_crossentropy','sgd')\n",
    "end = dt.datetime.now()\n",
    "twoLayer20NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 2 layers with 20 nodes each: {twoLayer20NodeModelFitTime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Layers, 10 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveLayer10NodeModel = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(784,)),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 2.2024 - accuracy: 0.2985 - val_loss: 1.1073 - val_accuracy: 0.6189\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.9475 - accuracy: 0.6586 - val_loss: 0.8694 - val_accuracy: 0.7086\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.7708 - accuracy: 0.7208 - val_loss: 0.7611 - val_accuracy: 0.7200\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.7175 - accuracy: 0.7351 - val_loss: 0.7053 - val_accuracy: 0.7314\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6881 - accuracy: 0.7376 - val_loss: 0.7083 - val_accuracy: 0.7536\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6577 - accuracy: 0.7593 - val_loss: 0.6586 - val_accuracy: 0.7776\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5998 - accuracy: 0.7952 - val_loss: 0.5949 - val_accuracy: 0.8114\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.5479 - accuracy: 0.8235 - val_loss: 0.5327 - val_accuracy: 0.8442\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4929 - accuracy: 0.8540 - val_loss: 0.5391 - val_accuracy: 0.8457\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4524 - accuracy: 0.8638 - val_loss: 0.4700 - val_accuracy: 0.8555\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4225 - accuracy: 0.8734 - val_loss: 0.4559 - val_accuracy: 0.8679\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3908 - accuracy: 0.8866 - val_loss: 0.4450 - val_accuracy: 0.8732\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8843 - val_loss: 0.4299 - val_accuracy: 0.8746\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3627 - accuracy: 0.8947 - val_loss: 0.4095 - val_accuracy: 0.8852\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3582 - accuracy: 0.8965 - val_loss: 0.4010 - val_accuracy: 0.8902\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3361 - accuracy: 0.8994 - val_loss: 0.4399 - val_accuracy: 0.8741\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3374 - accuracy: 0.8999 - val_loss: 0.3948 - val_accuracy: 0.8887\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3241 - accuracy: 0.9048 - val_loss: 0.3964 - val_accuracy: 0.8903\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3122 - accuracy: 0.9074 - val_loss: 0.3968 - val_accuracy: 0.8913\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3116 - accuracy: 0.9060 - val_loss: 0.4121 - val_accuracy: 0.8859\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.9037 - val_loss: 0.3791 - val_accuracy: 0.8941\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3093 - accuracy: 0.9110 - val_loss: 0.3875 - val_accuracy: 0.8897\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2946 - accuracy: 0.9116 - val_loss: 0.3831 - val_accuracy: 0.8951\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2904 - accuracy: 0.9160 - val_loss: 0.3792 - val_accuracy: 0.8959\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3003 - accuracy: 0.9119 - val_loss: 0.3909 - val_accuracy: 0.8922\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2856 - accuracy: 0.9164 - val_loss: 0.3783 - val_accuracy: 0.8995\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2758 - accuracy: 0.9199 - val_loss: 0.3861 - val_accuracy: 0.8922\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2775 - accuracy: 0.9230 - val_loss: 0.3755 - val_accuracy: 0.8990\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2759 - accuracy: 0.9199 - val_loss: 0.3762 - val_accuracy: 0.8990\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2685 - accuracy: 0.9228 - val_loss: 0.3661 - val_accuracy: 0.8990\n",
      "Time taken to fit 5 layers with 10 nodes each: 0:00:25.039713\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(fiveLayer10NodeModel,'categorical_crossentropy','adam')\n",
    "end = dt.datetime.now()\n",
    "fiveLayer10NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 5 layers with 10 nodes each: {fiveLayer10NodeModelFitTime}')\n",
    "# Kaggle Score: 0.89285, User:Deemal Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 0s 704us/step - loss: 0.3804 - accuracy: 0.8937\n",
      "Test accuracy 0.8937301635742188\n"
     ]
    }
   ],
   "source": [
    "predictModel(fiveLayer10NodeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Layers, 20 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveLayer20NodeModel = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(784,)),\n",
    "    keras.layers.Dense(20, activation = 'relu'),\n",
    "    keras.layers.Dense(20, activation = 'relu'),\n",
    "    keras.layers.Dense(20, activation = 'relu'),\n",
    "    keras.layers.Dense(20, activation = 'relu'),\n",
    "    keras.layers.Dense(20, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 3.0041 - accuracy: 0.2936 - val_loss: 0.8736 - val_accuracy: 0.6967\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.8004 - accuracy: 0.7367 - val_loss: 0.6332 - val_accuracy: 0.7940\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6021 - accuracy: 0.8099 - val_loss: 0.5461 - val_accuracy: 0.8336\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4943 - accuracy: 0.8480 - val_loss: 0.5029 - val_accuracy: 0.8483\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.4496 - accuracy: 0.8630 - val_loss: 0.4617 - val_accuracy: 0.8707\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3972 - accuracy: 0.8837 - val_loss: 0.4120 - val_accuracy: 0.8766\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3586 - accuracy: 0.8938 - val_loss: 0.3842 - val_accuracy: 0.8879\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3380 - accuracy: 0.9009 - val_loss: 0.3802 - val_accuracy: 0.8882\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3078 - accuracy: 0.9088 - val_loss: 0.3854 - val_accuracy: 0.8922\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2924 - accuracy: 0.9130 - val_loss: 0.3618 - val_accuracy: 0.8982\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2900 - accuracy: 0.9120 - val_loss: 0.3731 - val_accuracy: 0.8937\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2763 - accuracy: 0.9171 - val_loss: 0.3635 - val_accuracy: 0.8954\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2789 - accuracy: 0.9156 - val_loss: 0.3525 - val_accuracy: 0.8989\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2624 - accuracy: 0.9221 - val_loss: 0.3602 - val_accuracy: 0.8995\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2493 - accuracy: 0.9254 - val_loss: 0.3576 - val_accuracy: 0.8958\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2524 - accuracy: 0.9232 - val_loss: 0.3658 - val_accuracy: 0.8925\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2419 - accuracy: 0.9295 - val_loss: 0.3365 - val_accuracy: 0.9063\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2274 - accuracy: 0.9333 - val_loss: 0.3148 - val_accuracy: 0.9103\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2162 - accuracy: 0.9352 - val_loss: 0.2992 - val_accuracy: 0.9169\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2307 - accuracy: 0.9301 - val_loss: 0.3069 - val_accuracy: 0.9151\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2286 - accuracy: 0.9318 - val_loss: 0.2836 - val_accuracy: 0.9226\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1956 - accuracy: 0.9409 - val_loss: 0.3019 - val_accuracy: 0.9181\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1985 - accuracy: 0.9386 - val_loss: 0.2908 - val_accuracy: 0.9219\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1978 - accuracy: 0.9407 - val_loss: 0.3093 - val_accuracy: 0.9185\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1905 - accuracy: 0.9423 - val_loss: 0.3108 - val_accuracy: 0.9220\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1847 - accuracy: 0.9428 - val_loss: 0.3081 - val_accuracy: 0.9215\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1818 - accuracy: 0.9459 - val_loss: 0.2903 - val_accuracy: 0.9272\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1702 - accuracy: 0.9506 - val_loss: 0.2929 - val_accuracy: 0.9267\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1657 - accuracy: 0.9494 - val_loss: 0.3118 - val_accuracy: 0.9215\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1656 - accuracy: 0.9498 - val_loss: 0.3238 - val_accuracy: 0.9184\n",
      "Time taken to fit 5 layers with 20 nodes each: 0:00:23.558120\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(fiveLayer20NodeModel,'categorical_crossentropy','adam')\n",
    "end = dt.datetime.now()\n",
    "fiveLayer20NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 5 layers with 20 nodes each: {fiveLayer20NodeModelFitTime}')\n",
    "# Kaggle Score: 0.91928, User: Deemal Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 0s 642us/step - loss: 0.3156 - accuracy: 0.9184\n",
      "Test accuracy 0.9184126853942871\n"
     ]
    }
   ],
   "source": [
    "predictModel(fiveLayer20NodeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Layer, 50 Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveLayer50NodeModel = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(784,)),\n",
    "    keras.layers.Dense(50, activation = 'relu'),\n",
    "    keras.layers.Dense(50, activation = 'relu'),\n",
    "    keras.layers.Dense(50, activation = 'relu'),\n",
    "    keras.layers.Dense(50, activation = 'relu'),\n",
    "    keras.layers.Dense(50, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 2.1409 - accuracy: 0.5920 - val_loss: 0.4207 - val_accuracy: 0.8771\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.3880 - accuracy: 0.8864 - val_loss: 0.3498 - val_accuracy: 0.9001\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2616 - accuracy: 0.9213 - val_loss: 0.2750 - val_accuracy: 0.9203\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.2091 - accuracy: 0.9375 - val_loss: 0.2467 - val_accuracy: 0.9298\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1884 - accuracy: 0.9430 - val_loss: 0.2520 - val_accuracy: 0.9294\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1503 - accuracy: 0.9537 - val_loss: 0.2318 - val_accuracy: 0.9390\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1446 - accuracy: 0.9555 - val_loss: 0.2378 - val_accuracy: 0.9404\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1275 - accuracy: 0.9600 - val_loss: 0.2233 - val_accuracy: 0.9463\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1190 - accuracy: 0.9646 - val_loss: 0.2258 - val_accuracy: 0.9386\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.9652 - val_loss: 0.2218 - val_accuracy: 0.9401\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0985 - accuracy: 0.9709 - val_loss: 0.2356 - val_accuracy: 0.9445\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0860 - accuracy: 0.9744 - val_loss: 0.2336 - val_accuracy: 0.9442\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0813 - accuracy: 0.9748 - val_loss: 0.2437 - val_accuracy: 0.9415\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0879 - accuracy: 0.9734 - val_loss: 0.2129 - val_accuracy: 0.9495\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.1021 - accuracy: 0.9710 - val_loss: 0.2376 - val_accuracy: 0.9480\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0767 - accuracy: 0.9784 - val_loss: 0.3060 - val_accuracy: 0.9261\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0763 - accuracy: 0.9774 - val_loss: 0.2328 - val_accuracy: 0.9484\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0602 - accuracy: 0.9817 - val_loss: 0.2342 - val_accuracy: 0.9460\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0681 - accuracy: 0.9794 - val_loss: 0.2335 - val_accuracy: 0.9498\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0513 - accuracy: 0.9848 - val_loss: 0.2324 - val_accuracy: 0.9507\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0598 - accuracy: 0.9827 - val_loss: 0.2239 - val_accuracy: 0.9490\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.2431 - val_accuracy: 0.9505\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0486 - accuracy: 0.9856 - val_loss: 0.2222 - val_accuracy: 0.9507\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0516 - accuracy: 0.9843 - val_loss: 0.2504 - val_accuracy: 0.9468\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.2753 - val_accuracy: 0.9510\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0564 - accuracy: 0.9836 - val_loss: 0.2188 - val_accuracy: 0.9593\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0378 - accuracy: 0.9886 - val_loss: 0.2475 - val_accuracy: 0.9540\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0450 - accuracy: 0.9857 - val_loss: 0.2297 - val_accuracy: 0.9570\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.2612 - val_accuracy: 0.9567\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 0.2795 - val_accuracy: 0.9514\n",
      "Time taken to fit 5 layers with 50 nodes each: 0:00:28.519816\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(fiveLayer50NodeModel,'categorical_crossentropy','adam')\n",
    "end = dt.datetime.now()\n",
    "fiveLayer50NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 5 layers with 50 nodes each: {fiveLayer50NodeModelFitTime}')\n",
    "# Kaggle Score: 0.95139, Deemal Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 0s 700us/step - loss: 0.2472 - accuracy: 0.9545\n",
      "Test accuracy 0.9545238018035889\n"
     ]
    }
   ],
   "source": [
    "predictModel(fiveLayer50NodeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Layer, 100 Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveLayer100NodeModel = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(784,)),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 1.9150 - accuracy: 0.6888 - val_loss: 0.4015 - val_accuracy: 0.8888\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.2984 - accuracy: 0.9127 - val_loss: 0.2458 - val_accuracy: 0.9297\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1886 - accuracy: 0.9462 - val_loss: 0.2282 - val_accuracy: 0.9350\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9504 - val_loss: 0.2258 - val_accuracy: 0.9369\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1380 - accuracy: 0.9574 - val_loss: 0.2100 - val_accuracy: 0.9445\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1221 - accuracy: 0.9611 - val_loss: 0.3055 - val_accuracy: 0.9260\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1282 - accuracy: 0.9619 - val_loss: 0.2146 - val_accuracy: 0.9431\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1053 - accuracy: 0.9686 - val_loss: 0.2156 - val_accuracy: 0.9478\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9715 - val_loss: 0.2215 - val_accuracy: 0.9468\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9736 - val_loss: 0.1770 - val_accuracy: 0.9571\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9791 - val_loss: 0.2210 - val_accuracy: 0.9502\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0736 - accuracy: 0.9786 - val_loss: 0.1604 - val_accuracy: 0.9574\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9813 - val_loss: 0.1858 - val_accuracy: 0.9573\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0664 - accuracy: 0.9804 - val_loss: 0.1937 - val_accuracy: 0.9536\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.9810 - val_loss: 0.1922 - val_accuracy: 0.9566\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0564 - accuracy: 0.9847 - val_loss: 0.2531 - val_accuracy: 0.9478\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9810 - val_loss: 0.2116 - val_accuracy: 0.9453\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0452 - accuracy: 0.9863 - val_loss: 0.2120 - val_accuracy: 0.9554\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0482 - accuracy: 0.9860 - val_loss: 0.1939 - val_accuracy: 0.9611\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0505 - accuracy: 0.9866 - val_loss: 0.2678 - val_accuracy: 0.9524\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0430 - accuracy: 0.9876 - val_loss: 0.2797 - val_accuracy: 0.9529\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0354 - accuracy: 0.9908 - val_loss: 0.2088 - val_accuracy: 0.9597\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0446 - accuracy: 0.9882 - val_loss: 0.2708 - val_accuracy: 0.9599\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0565 - accuracy: 0.9864 - val_loss: 0.2007 - val_accuracy: 0.9623\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0341 - accuracy: 0.9909 - val_loss: 0.2612 - val_accuracy: 0.9610\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0481 - accuracy: 0.9874 - val_loss: 0.2083 - val_accuracy: 0.9660\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.2813 - val_accuracy: 0.9527\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0490 - accuracy: 0.9876 - val_loss: 0.1907 - val_accuracy: 0.9634\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0331 - accuracy: 0.9904 - val_loss: 0.2368 - val_accuracy: 0.9673\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0293 - accuracy: 0.9921 - val_loss: 0.2058 - val_accuracy: 0.9654\n",
      "Time taken to fit 5 layers with 100 nodes each: 0:00:34.425971\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(fiveLayer100NodeModel,'categorical_crossentropy','adam')\n",
    "end = dt.datetime.now()\n",
    "fiveLayer100NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 5 layers with 100 nodes each: {fiveLayer100NodeModelFitTime}')\n",
    "# Kaggle Score: 0.96514, Deemal Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 0s 793us/step - loss: 0.1875 - accuracy: 0.9675\n",
      "Test accuracy 0.9674603343009949\n"
     ]
    }
   ],
   "source": [
    "predictModel(fiveLayer100NodeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Layer, 150 Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveLayer150NodeModel = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(784,)),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 2.3259 - accuracy: 0.7246 - val_loss: 0.3182 - val_accuracy: 0.9086\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.9258 - val_loss: 0.2412 - val_accuracy: 0.9333\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.9464 - val_loss: 0.2290 - val_accuracy: 0.9381\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9494 - val_loss: 0.2290 - val_accuracy: 0.9359\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1426 - accuracy: 0.9581 - val_loss: 0.1864 - val_accuracy: 0.9459\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1152 - accuracy: 0.9653 - val_loss: 0.2115 - val_accuracy: 0.9412\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9688 - val_loss: 0.2182 - val_accuracy: 0.9456\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9708 - val_loss: 0.1880 - val_accuracy: 0.9522\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9730 - val_loss: 0.1908 - val_accuracy: 0.9524\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0762 - accuracy: 0.9788 - val_loss: 0.1870 - val_accuracy: 0.9586\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0703 - accuracy: 0.9795 - val_loss: 0.1855 - val_accuracy: 0.9582\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9790 - val_loss: 0.1922 - val_accuracy: 0.9571\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9814 - val_loss: 0.2241 - val_accuracy: 0.9559\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9842 - val_loss: 0.2811 - val_accuracy: 0.9461\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0803 - accuracy: 0.9787 - val_loss: 0.1963 - val_accuracy: 0.9585\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0460 - accuracy: 0.9864 - val_loss: 0.2146 - val_accuracy: 0.9597\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0680 - accuracy: 0.9835 - val_loss: 0.2003 - val_accuracy: 0.9588\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0393 - accuracy: 0.9897 - val_loss: 0.1703 - val_accuracy: 0.9645\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0480 - accuracy: 0.9885 - val_loss: 0.2770 - val_accuracy: 0.9465\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9838 - val_loss: 0.2056 - val_accuracy: 0.9644\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0431 - accuracy: 0.9889 - val_loss: 0.2570 - val_accuracy: 0.9603\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.9852 - val_loss: 0.2483 - val_accuracy: 0.9634\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0521 - accuracy: 0.9888 - val_loss: 0.1883 - val_accuracy: 0.9659\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9916 - val_loss: 0.1988 - val_accuracy: 0.9686\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0297 - accuracy: 0.9935 - val_loss: 0.2040 - val_accuracy: 0.9657\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0355 - accuracy: 0.9907 - val_loss: 0.2923 - val_accuracy: 0.9551\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9845 - val_loss: 0.1897 - val_accuracy: 0.9641\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.9908 - val_loss: 0.2360 - val_accuracy: 0.9622\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9943 - val_loss: 0.3049 - val_accuracy: 0.9556\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.9925 - val_loss: 0.3005 - val_accuracy: 0.9618\n",
      "Time taken to fit 5 layers with 150 nodes each: 0:00:41.499968\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(fiveLayer150NodeModel,'categorical_crossentropy','adam')\n",
    "end = dt.datetime.now()\n",
    "fiveLayer150NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 5 layers with 150 nodes each: {fiveLayer150NodeModelFitTime}')\n",
    "# Kaggle Score 0.95967,  Deemal Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 0s 951us/step - loss: 0.2804 - accuracy: 0.9629\n",
      "Test accuracy 0.962936520576477\n"
     ]
    }
   ],
   "source": [
    "predictModel(fiveLayer150NodeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Layer, 150 Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenLayer150NodeModel = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(784,)),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(150, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.8543 - accuracy: 0.7384 - val_loss: 0.2518 - val_accuracy: 0.9307\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.2363 - accuracy: 0.9357 - val_loss: 0.2761 - val_accuracy: 0.9268\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.1808 - accuracy: 0.9506 - val_loss: 0.2252 - val_accuracy: 0.9418\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.1480 - accuracy: 0.9599 - val_loss: 0.1962 - val_accuracy: 0.9531\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.1285 - accuracy: 0.9665 - val_loss: 0.1746 - val_accuracy: 0.9576\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.1178 - accuracy: 0.9708 - val_loss: 0.1846 - val_accuracy: 0.9567\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.1174 - accuracy: 0.9724 - val_loss: 0.2025 - val_accuracy: 0.9562\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0969 - accuracy: 0.9770 - val_loss: 0.1830 - val_accuracy: 0.9614\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0939 - accuracy: 0.9762 - val_loss: 0.2488 - val_accuracy: 0.9532\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.9802 - val_loss: 0.2110 - val_accuracy: 0.9585\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.9800 - val_loss: 0.2525 - val_accuracy: 0.9569\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0903 - accuracy: 0.9788 - val_loss: 0.2578 - val_accuracy: 0.9535\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0737 - accuracy: 0.9826 - val_loss: 0.2217 - val_accuracy: 0.9626\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.9850 - val_loss: 0.2118 - val_accuracy: 0.9616\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0688 - accuracy: 0.9848 - val_loss: 0.2027 - val_accuracy: 0.9656\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0603 - accuracy: 0.9863 - val_loss: 0.2042 - val_accuracy: 0.9605\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0578 - accuracy: 0.9872 - val_loss: 0.2446 - val_accuracy: 0.9630\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0402 - accuracy: 0.9907 - val_loss: 0.2470 - val_accuracy: 0.9522\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0578 - accuracy: 0.9871 - val_loss: 0.2330 - val_accuracy: 0.9595\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0507 - accuracy: 0.9880 - val_loss: 0.1968 - val_accuracy: 0.9631\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0456 - accuracy: 0.9899 - val_loss: 0.2569 - val_accuracy: 0.9637\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0715 - accuracy: 0.9884 - val_loss: 0.2716 - val_accuracy: 0.9597\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0554 - accuracy: 0.9871 - val_loss: 0.2380 - val_accuracy: 0.9656\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0399 - accuracy: 0.9911 - val_loss: 0.3177 - val_accuracy: 0.9659\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0520 - accuracy: 0.9892 - val_loss: 0.2358 - val_accuracy: 0.9631\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0498 - accuracy: 0.9897 - val_loss: 0.5442 - val_accuracy: 0.9644\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.9847 - val_loss: 0.1910 - val_accuracy: 0.9664\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0336 - accuracy: 0.9928 - val_loss: 0.2222 - val_accuracy: 0.9675\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0427 - accuracy: 0.9901 - val_loss: 0.2967 - val_accuracy: 0.9597\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.9827 - val_loss: 0.2364 - val_accuracy: 0.9597\n",
      "Time taken to fit 10 layers with 150 nodes each: 0:00:50.160994\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(tenLayer150NodeModel,'categorical_crossentropy','adam')\n",
    "end = dt.datetime.now()\n",
    "tenLayer150NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 10 layers with 150 nodes each: {tenLayer150NodeModelFitTime}')\n",
    "# Kaggle Score 0.95528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.9593\n",
      "Test accuracy 0.9592857360839844\n"
     ]
    }
   ],
   "source": [
    "predictModel(tenLayer150NodeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Layer, 200 Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenLayer200NodeModel = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(784,)),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "690/690 [==============================] - 3s 4ms/step - loss: 0.9061 - accuracy: 0.7468 - val_loss: 0.2373 - val_accuracy: 0.9340\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.2415 - accuracy: 0.9381 - val_loss: 0.3030 - val_accuracy: 0.9190\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.2702 - accuracy: 0.9274 - val_loss: 0.2032 - val_accuracy: 0.9478\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1666 - accuracy: 0.9606 - val_loss: 0.2088 - val_accuracy: 0.9503\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1177 - accuracy: 0.9708 - val_loss: 0.2782 - val_accuracy: 0.9465\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1446 - accuracy: 0.9686 - val_loss: 0.2196 - val_accuracy: 0.9518\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1198 - accuracy: 0.9711 - val_loss: 0.2120 - val_accuracy: 0.9603\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1001 - accuracy: 0.9744 - val_loss: 0.1796 - val_accuracy: 0.9619\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1040 - accuracy: 0.9770 - val_loss: 0.1731 - val_accuracy: 0.9622\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.1002 - accuracy: 0.9757 - val_loss: 0.2658 - val_accuracy: 0.9589\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0872 - accuracy: 0.9798 - val_loss: 0.1937 - val_accuracy: 0.9599\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 0.2073 - val_accuracy: 0.9648\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0697 - accuracy: 0.9834 - val_loss: 0.2631 - val_accuracy: 0.9541\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0829 - accuracy: 0.9822 - val_loss: 0.2051 - val_accuracy: 0.9645\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0930 - accuracy: 0.9782 - val_loss: 0.1828 - val_accuracy: 0.9648\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0519 - accuracy: 0.9883 - val_loss: 0.2367 - val_accuracy: 0.9619\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0636 - accuracy: 0.9868 - val_loss: 0.2485 - val_accuracy: 0.9578\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0592 - accuracy: 0.9873 - val_loss: 0.2336 - val_accuracy: 0.9630\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9857 - val_loss: 0.2391 - val_accuracy: 0.9551\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0771 - accuracy: 0.9818 - val_loss: 0.2087 - val_accuracy: 0.9663\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0510 - accuracy: 0.9899 - val_loss: 0.2466 - val_accuracy: 0.9667\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0595 - accuracy: 0.9865 - val_loss: 0.3984 - val_accuracy: 0.9648\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0609 - accuracy: 0.9882 - val_loss: 0.2822 - val_accuracy: 0.9648\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0621 - accuracy: 0.9893 - val_loss: 0.2566 - val_accuracy: 0.9605\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0533 - accuracy: 0.9898 - val_loss: 0.2623 - val_accuracy: 0.9597\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0539 - accuracy: 0.9895 - val_loss: 0.1847 - val_accuracy: 0.9687\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0485 - accuracy: 0.9884 - val_loss: 0.2058 - val_accuracy: 0.9691\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0501 - accuracy: 0.9896 - val_loss: 0.2151 - val_accuracy: 0.9684\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0404 - accuracy: 0.9909 - val_loss: 0.3437 - val_accuracy: 0.9531\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 2s 3ms/step - loss: 0.0634 - accuracy: 0.9875 - val_loss: 0.3512 - val_accuracy: 0.9642\n",
      "Time taken to fit 10 layers with 150 nodes each: 0:01:05.512456\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "fitModel(tenLayer200NodeModel,'categorical_crossentropy','adam')\n",
    "end = dt.datetime.now()\n",
    "tenLayer200NodeModelFitTime = end - start\n",
    "print(f'Time taken to fit 10 layers with 150 nodes each: {tenLayer200NodeModelFitTime}')\n",
    "# Kaggle Score: 0.96203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 1s 1ms/step - loss: 0.3202 - accuracy: 0.9640\n",
      "Test accuracy 0.9639682769775391\n"
     ]
    }
   ],
   "source": [
    "predictModel(tenLayer200NodeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesPerModel = [10,20,10,20,50,100,150,150,200]\n",
    "layersPerModel = [2,2,5,5,5,5,5,10,10]\n",
    "timePerModel = [twoLayer10NodeModelFitTime,twoLayer20NodeModelFitTime,fiveLayer10NodeModelFitTime,\n",
    "               fiveLayer20NodeModelFitTime,fiveLayer50NodeModelFitTime,fiveLayer100NodeModelFitTime,\n",
    "               fiveLayer150NodeModelFitTime,tenLayer150NodeModelFitTime,tenLayer200NodeModelFitTime]\n",
    "trainingSetAccuracy = [0.8483, 0.8739, 0.9228, 0.9506, 0.9913, 0.9921, 0.9943,0.9928, 0.9909]\n",
    "testingSetAccuracy = [0.826, 0.7987, 0.8937, 0.9184, 0.9545, 0.9675, 0.9629,0.9593, 0.9640]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Layers</th>\n",
       "      <th>Nodes Per Layer</th>\n",
       "      <th>Processing Time</th>\n",
       "      <th>Traing Set Accuracy</th>\n",
       "      <th>Testing Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:24.243876</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>0.8260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>00:00:22.404917</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.7987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:25.039713</td>\n",
       "      <td>0.9228</td>\n",
       "      <td>0.8937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>00:00:23.558120</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.9184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>00:00:28.519816</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>00:00:34.425971</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>00:00:41.499968</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.9629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>00:00:50.160994</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>00:01:05.512456</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>0.9640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Layers  Nodes Per Layer Processing Time  Traing Set Accuracy  \\\n",
       "0                 2               10 00:00:24.243876               0.8483   \n",
       "1                 2               20 00:00:22.404917               0.8739   \n",
       "2                 5               10 00:00:25.039713               0.9228   \n",
       "3                 5               20 00:00:23.558120               0.9506   \n",
       "4                 5               50 00:00:28.519816               0.9913   \n",
       "5                 5              100 00:00:34.425971               0.9921   \n",
       "6                 5              150 00:00:41.499968               0.9943   \n",
       "7                10              150 00:00:50.160994               0.9928   \n",
       "8                10              200 00:01:05.512456               0.9909   \n",
       "\n",
       "   Testing Set Accuracy  \n",
       "0                0.8260  \n",
       "1                0.7987  \n",
       "2                0.8937  \n",
       "3                0.9184  \n",
       "4                0.9545  \n",
       "5                0.9675  \n",
       "6                0.9629  \n",
       "7                0.9593  \n",
       "8                0.9640  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaryDF = pd.DataFrame({\n",
    "    'Number of Layers': layersPerModel,\n",
    "    'Nodes Per Layer': nodesPerModel,\n",
    "    'Processing Time':timePerModel,\n",
    "    'Traing Set Accuracy':trainingSetAccuracy,\n",
    "    'Testing Set Accuracy':testingSetAccuracy\n",
    "})\n",
    "summaryDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Management Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We begin by exploring the data within this dataset. We can see that that the training data set contains 42000 rows of data and 784 columns of explanatory variables. Each column represent a single pixel of the image and each image is a 28 x 28 pixel. We look at the corresponding labels to get an idea of how which number the explanatory variables the image belongs to. Because these labels will be used within a neural network for the purpose of properly determining the image, we need to convert the labels in to categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We develop multiple neural network models with different hyperparameters to tune the model in order to get a high accuracy not only from training but also when we test it. The modeling method being used here is a MLP, Multiple Layer Perceptron. In order to properly implement the MLP are using the Sequential API. The Sequential API will help us with our classification MLP to properly determine the digit from the test data. We create our train, test, and validation set before we start the implemention. We begin implementing the neural network by creating a keras model which comes with tensorflow which is the package that will allow us to build our model. The model requires and input layer, the hidden layer, and the outer layer. We must transform the model to be ready for a 784 input shape because our dataset has 784 expalantory variables that help produce the labels. The layers use the ReLU, or Rectified Linear Unit, which is a good choice to use when starting to create the models. We use a softmax in the outer layer because it calculates the probability that the data belongs to a specific class. The sum of all the softmax classification probabilities should add up to one. Once the layers and have been set up we want to compile the model using the categorical_crossentropy as our loss function. We want to optimize the model with an adam optimizer which is an adaptive learning rate algorithm. The metric used is accuracy because we want to see how accurate the model is when correctly classifying the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We have created 9 different models with a different mix of layers and nodes per layer to determine the accuracy of each one. The accuracy will tell us how well the model performed with the training set and the validation set. If the validation set's accuracy is fairly close to the training set's and the accuracy is a score that we like to see, for example 95%, then it is fair to say that there is little to no overfitting/underfitting occuring and we have a solid model. Analyzing at what we have created are two, two layer models each where the first one has 10 nodes per layer and the other one has 20 nodes per layer. The accuracy scores we get for the training and testing set are not bad coming to around 84.8% for the first model and 87.3% for the second model. This can definitely be improved so we have 5 more models that have 5 layers each with nodes that are 10,20,50,100,150, respectively. The accuracy came out a lot better with the 5 layers getting 92.2%, 95%, 99.1%, 99.2%, 99.4%. The testing set came very close to around 96% for each but this is to be expected as the model would favor the training set a little more. We also ran 2 10 layer models with 150 nodes and 200 nodes. These also came to about 99%. At this point because the accuracies are so close to one another we want to look at the processing time. The best accuracy to time ratio would probably be model 6 because it has a short processing time with a high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. From the benchmark dataframe we can see that going any higher on the layers would not provide much benefit. Because the processing time increase by 10 seconds for every 50 nodes added it would be a waste of time to perform any more models only to maybe see an improvement of 0.1% improvement in the model. For our use the instituitons use, I would recommend we use the 5 layer model with 100 nodes per layer because of the good accuracy to processing time ratio. We get an incredibly good accuracy score while not having to spend more time determining how many more models to test. The settings for this model used the Sequential API with a categorical_crossentropy loss function and the adam optimizer in order to achieve the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
